{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6db4229",
   "metadata": {},
   "source": [
    "# 네이버뉴스 웹 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efcb95c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "\n",
    "import sys             # 시스템 관련\n",
    "import os              # 시스템 관련\n",
    "import numpy as np    # 행렬 연산을 위한\n",
    "import requests       # HTTP 호출\n",
    "import re             # 정규표현식을 이용한 문자열 매칭\n",
    "from bs4 import BeautifulSoup   # 데이터 정제\n",
    "from tqdm.notebook import tqdm  # 반복문 진행과정 시각화\n",
    "import nltk           # 자연어처리 라이브러리\n",
    "from konlpy.tag import Okt; okt = Okt() # 한국어 자연어 처리(품사분석)\n",
    "import matplotlib.pyplot as plt # 그래프\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS  # 워드크라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce91ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "\n",
    "news_list = []        # 제목 + 요약내용 담을 리스트\n",
    "keyword = '대한항공'     # 검색어\n",
    "page_num = 1             # 뉴스검색 페이지\n",
    "ds = '2021.01.01'        # 검색 날짜지정(시작일)\n",
    "de = '2021.03.31'        # 검색 날짜지정(종료일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b275e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 뉴스 크롤링\n",
    "# 정해진 날짜내에서 최대 4천건을 검색\n",
    "\n",
    "last = False           # while 반복문을 돌리기위한 변수설정\n",
    "pbar = tqdm(total=3990) # tqdm 진행바를 3990에서 끝나도록 설정\n",
    "while last == False:  # last=True로 될때까지 반복\n",
    "    url = 'https://search.naver.com/search.naver?&where=news&sm=tab_pge\\\n",
    "    &query={0}&sort=0&photo=0&field=0&pd=3&ds={1}&de={2}&mynews=0\\\n",
    "    &office_type=0&office_section_code=0&nso=so:r,p:,a:all&start={3}'.format(\n",
    "    keyword,ds,de,str(page_num))           # 뉴스페이지 url, 위에서 설정한 변수들을 .format으로 넣어줌\n",
    "    headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36'}  # 웹크롤링 오류방지를 위해 헤더설정\n",
    "    \n",
    "    res = requests.get(url, headers = headers)              # requests를 통해 url의 HTML을 가져옴\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')           # HTML 페이지 분석\n",
    "    \n",
    "    # 뉴스 제목,내용요약 부분이 있는 ul(class:list_news)를 기사별(10개)로 가져온다.\n",
    "    li_list = soup.find('ul', {'class':'list_news'}).find_all('li', {'id':re.compile('sp_nws.*')})\n",
    "    area_list = [li.find('div', {'class':'news_area'}) for li in li_list]    # 제목을 가져오기 위한 리스트 반복문\n",
    "    a_list = [area.find('a', {'class':'news_tit'}) for area in area_list]    \n",
    "    div_list = [li.find('div', {'class':'dsc_wrap'}) for li in li_list]      # 내용요약을 가져오기 위한 리스트 반복문\n",
    "\n",
    "    for x,y in zip(a_list, div_list):    # 제목과 내용요약을 news_list에 담는 반복문(기사10개)\n",
    "        news_list.append(x.get('title'))\n",
    "        news_list.append(y.text)\n",
    "        \n",
    "    page_num += 10   # 페이지 넘김(네이버는 페이지가 1,11,21~증가함)\n",
    "    pbar.update(10)  # 반복문이 한번 돌때마다 tqdm 진행바를 10 씩 채움\n",
    "    \n",
    "    # 마지막 페이지에서 반복문을 끝내기 위해 페이지표기 숫자를 가져옴\n",
    "    page = soup.find('div', {'class':'sc_page_inner'})\n",
    "    page_a_list = page.find_all('a')\n",
    "    pages = [a.text for a in page_a_list]\n",
    "    \n",
    "    if page_num == 91:    # 네이버는 페이지가 10이어도 뒷페이지가 자동으로 표시되지 않기때문에 넘김\n",
    "        continue\n",
    "    elif page_num == (int(pages[-1])*10-9): # 마지막페이지에서 last=True로 설정\n",
    "        last = True\n",
    "\n",
    "pbar.close()          # 반복문이 끝나면 tqdm 진행바를 끝냄\n",
    "#print(news_list)     # 확인용 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b7e2b",
   "metadata": {},
   "source": [
    "# 웹크롤링한 데이터 자연어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링한 기사들을 Okt를 사용하여 품사분석하고 필요없는 품사 제거\n",
    "\n",
    "results = []    # 최종 결과물을 담을 리스트\n",
    "for line in news_list:\n",
    "    intm = okt.pos(line, norm=True, stem=True)    # Okt를 사용해 한국어 형태소 분석(norm:정규화, stem:어간추출)\n",
    "    \n",
    "    r = []    # 필요없는 품사를 제외한 형태소들을 담을 리스트\n",
    "    for word in intm:\n",
    "        if not word[1] in ['Puctuation', 'Josa', 'Foreign', 'Number', 'Verb']:    # 개인적으로 판단하여 제거하자\n",
    "            r.append(word[0])                                            # ('단어','품사')형태라 word[0],word[1]\n",
    "    \n",
    "    r1 = (' '.join(r)).strip()    # 필요한 형태소들만 다시 합쳐 line화(문장) 만듬\n",
    "    results.append(r1)\n",
    "\n",
    "#print(results)    # 확인용 출력  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e260c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트에 담겨있는 문장들을 하나의 텍스트로 만듬\n",
    "\n",
    "collect_text = ''\n",
    "\n",
    "for each_line in results:\n",
    "    collect_text = collect_text + each_line + '\\n'\n",
    "    \n",
    "#print(collect_text) # 확인용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804630da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 텍스트를 형태소별로 나누고 불용어를 지정하여 걸러내기\n",
    "\n",
    "tokens_ko = okt.morphs(collect_text)    # 형태소별로 나누기\n",
    "\n",
    "stop_words = ['.',',','\\n','…','(',')','..','개','변','약','...',\"'\",'\"','·','[',']','=','’','-','있다','등','이',\n",
    "             '들','것','화','원','위해','~']    # 불용어 지정하기\n",
    "\n",
    "tokens_ko = [each_word for each_word in tokens_ko\n",
    "            if each_word not in stop_words]         # 불용어 걸러내기\n",
    "\n",
    "#tokens_ko     # 결과물 확인하면서 불용어 추가할것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed8697",
   "metadata": {},
   "source": [
    "# 자연어 처리를 통한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10540b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어의 데이터 탐색을 쉽게해주는 nltk.Text\n",
    "# nltk.Text를 이용해 그래프를 그리거나 워드크라우드를 만들 수 있음\n",
    "\n",
    "ko = nltk.Text(tokens_ko, name='네이버기사')\n",
    "ko.vocab().most_common(10)    # 빈도수가 가장 많은 순으로 정리(개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037757b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib 그래프에 한글이 문제없이 표기되도록 하는 부분\n",
    "\n",
    "import platform\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    path = 'c:/Windows/Fonts/malgun.ttf'\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unkown system... sorry~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도수를 y축으로 하는 그래프를 그림\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "ko.plot(10)                # (보여줄 단어 개수)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 빈도수를 보여주는 워드크라우드 만들기\n",
    "\n",
    "data = ko.vocab().most_common(50)    # 빈도수 순으로 최대 50개의 단어를 추려냄\n",
    "\n",
    "# 딕셔너리화 시킨 후 워드크라우드 만들기\n",
    "wordcloud = WordCloud(font_path=path,\n",
    "                     relative_scaling=0.2,\n",
    "                     background_color='white').generate_from_frequencies(dict(data))\n",
    "\n",
    "# 워드크라우드를 그리기(Matplotlib)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
